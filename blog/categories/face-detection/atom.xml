<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Face Detection | Ensar Hamzaçebi]]></title>
  <link href="http://ensr.github.io/blog/categories/face-detection/atom.xml" rel="self"/>
  <link href="http://ensr.github.io/"/>
  <updated>2016-05-11T17:55:20+03:00</updated>
  <id>http://ensr.github.io/</id>
  <author>
    <name><![CDATA[Ensar Hamzaçebi]]></name>
    <email><![CDATA[hamzacebi.ensar@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Android Face Detection 04 - Classification]]></title>
    <link href="http://ensr.github.io/blog/2016/02/22/android-face-detection-04-classification/"/>
    <updated>2016-02-22T14:21:26+02:00</updated>
    <id>http://ensr.github.io/blog/2016/02/22/android-face-detection-04-classification</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/face_classification.jpg">
Classification, tespit edilen yüz'ün gülüp gülmediğini tespit etmemizi sağlar. Bunu yaparkende yüzün gülüp gülmediğiyle alakalı 0 ile 1 arasında bir sayı döner.<!-- more --> Bu yazımızda face detection ile alakalı önceki yazılarımızda başladığımız proje üzerinden devam ediceğimiz için önce onları okumanızda fayda var:</p>

<ol>
<li><a href="http://ensr.github.io/blog/2016/02/18/android-face-detection/">Android Face Detection 01 - Başlangıç</a></li>
<li><a href="http://ensr.github.io/blog/2016/02/18/android-face-detection-02/">Android Face Detection 02 - Yüzleri Kare içine alma</a></li>
<li><a href="http://ensr.github.io/blog/2016/02/19/android-face-detection-03-landmarks-kullanimi">Android Face Detection 03 - Landmarks Kullanımı</a></li>
</ol>


<p>MainActivit'in <code>onCreate</code> methodunda oluşturduğumuz <code>FaceDetector</code> nesnesini aşşağıdaki gibi güncelliyoruz</p>

<pre><code class="java">FaceDetector detector = new FaceDetector.Builder(getApplicationContext())
            .setTrackingEnabled(false)
            .setLandmarkType(FaceDetector.ALL_LANDMARKS)
            .setClassificationType(FaceDetector.ALL_CLASSIFICATIONS)
            .build();
</code></pre>

<p>Eğer landmark kullanmak istemiyorsanız <code>setLandmarkType</code> opsiyonunu kaldırabilirsiniz. Bu procces'in hızlanmasını sağlayacaktır. Yine <code>onCreate</code>&lsquo;in içerisinde kaynak resmimizi alıyoruz</p>

<pre><code class="java">InputStream stream = getResources().openRawResource(R.raw.image03);
</code></pre>

<p>Daha sonra <code>CustomView</code> sınıfımıza şu fonksiyonu ekliyoruz.</p>

<pre><code class="java">private void detectFaceCharacteristics(Canvas canvas, double scale) {
    Paint paint = new Paint();
    paint.setColor(Color.RED);
    paint.setStyle(Paint.Style.FILL);
    paint.setStrokeWidth(1);
    paint.setTextSize(25.0f);

    for (int i = 0; i &lt; mFaces.size(); ++i) {
        Face face = mFaces.valueAt(i);
        float cx = (float)(face.getPosition().x * scale);
        float cy = (float) (face.getPosition().y * scale);
        canvas.drawText(String.valueOf(face.getIsSmilingProbability()), cx, cy + 10.0f, paint);
    }
}
</code></pre>

<p>Burada kilit nokta <code>face.getIsSmilingProbability()</code>. Bu bize, tespit edilen yüzün gülüyor olma olasılığını 0 ile 1 arasında bir sayı vererek söylemektedir.</p>

<p>Bu yeni fonksiyonumuzu <code>CustomView</code> sımıfımızdaki <code>onDraw()</code> fonksiyonumuzda <code>drawFaceAnnotations()</code> fonksiyonu yerine çağırıyoruz.</p>

<pre><code class="java">detectFaceCharacteristics(canvas, scale);
</code></pre>

<p>Projeyi run ettiğimizde kaynak olarak verdiğimiz resimdeki yüzlerin gülümseme oranlarını bize verdiğini görebilirsiniz.</p>

<p><img class="center" src="/images/face_class.png"></p>

<p>Tavsiyelerinizi önerilerinizi ve ya sorularınızı bekliyorum. İyi çalışmalar.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Android Face Detection 03 - Landmarks Kullanımı]]></title>
    <link href="http://ensr.github.io/blog/2016/02/19/android-face-detection-03-landmarks-kullanimi/"/>
    <updated>2016-02-19T16:28:21+02:00</updated>
    <id>http://ensr.github.io/blog/2016/02/19/android-face-detection-03-landmarks-kullanimi</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/face_poster.jpg"></p>

<p>Arkadaşlar bu yazımda landmarklardan bahsetmeye çalışıcam biraz. Evet landmarklar en basit haliyle Face API tarafından tespit edilen yüzler üzerindeki özel noktadara verilen isimdir. Yani sol göz, sağ göz, burun ucu, dudak sonu gibi yüzün belirli yerlerini işaret eden noktalardır.</p>

<!-- more -->


<p>Şimdi de landmarkları nasıl kullanıyoruz onu görelim. MainActivity'de <code>onCreate</code> methodumuza bakalım.</p>

<pre><code class="java MainActivity.java">@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    InputStream stream = getResources().openRawResource(R.raw.image03);
    Bitmap bitmap = BitmapFactory.decodeStream(stream);

    FaceDetector detector = new FaceDetector.Builder(getApplicationContext())
            .setTrackingEnabled(false)
            .setLandmarkType(FaceDetector.ALL_LANDMARKS)
            .build();

    Frame frame = new Frame.Builder().setBitmap(bitmap).build();
    SparseArray&lt;Face&gt; faces = detector.detect(frame);

    CustomView overlay = (CustomView) findViewById(R.id.customView);
    overlay.setContent(bitmap, faces);

    detector.release();

}
</code></pre>

<p>Burada önceki örneklerimizden farklı olarak Face detectorumuzu oluştururken <code>setLandmarkType(FaceDetector.ALL_LANDMARKS)</code> &lsquo;ın eklenmiş olmasıdır.</p>

<p>Bir sonraki adım, daha önceden oluşturduğumuz <code>CustomView</code> sınıfına landmarkları işaretliyecek fonksiyonu eklemek.</p>

<pre><code class="java CustomView.java">private void drawFaceAnnotations(Canvas canvas, double scale) {
    Paint paint = new Paint();
    paint.setColor(Color.GREEN);
    paint.setStyle(Paint.Style.STROKE);
    paint.setStrokeWidth(5);

    for (int i = 0; i &lt; mFaces.size(); ++i) {
        Face face = mFaces.valueAt(i);
        for (Landmark landmark : face.getLandmarks()) {
            int cx = (int) (landmark.getPosition().x * scale);
            int cy = (int) (landmark.getPosition().y * scale);
            canvas.drawCircle(cx, cy, 10, paint);
        }
    }

}
</code></pre>

<p>Sınıfın tamamını merak edenler konu ile alakalı bir önceki <a href="http://ensr.github.io/blog/2016/02/18/android-face-detection-02/">yazıya</a> bakabilirler.</p>

<p>Fonksiyonu ekledikten sonra <code>onDraw()</code> &lsquo;da <code>drawFaceRectangle()</code> yerine yeni eklediğimiz <code>drawFaceAnnotations()</code> fonksiyonunu çağırmayı unutmuyoruz tabiki.</p>

<pre><code>drawFaceAnnotations(canvas, scale);
</code></pre>

<p>Uygulamamızı bu şekilde çalıştırdığımızda Face Detection'a bitmap olarak verdiğiniz yüz resminde şu şekilde landmarkların işaretlendiğini görebilirsiniz.</p>

<p><img class="center" src="/images/face_landmarks.png"></p>

<p>Şimdilik burada bırakıyorum ancan sonraki yazıda biraz da <code>classification</code> &lsquo;dan bahsedicez. Herhangi bir hata ile karşılaşırsanız yorum yazmayı unutmayın. Kendinize iyi bakın.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Android Face Detection 02 - Yüzleri Kara İçine Alma]]></title>
    <link href="http://ensr.github.io/blog/2016/02/18/android-face-detection-02-yuzleri-kara-icine-alma/"/>
    <updated>2016-02-18T17:32:10+02:00</updated>
    <id>http://ensr.github.io/blog/2016/02/18/android-face-detection-02-yuzleri-kara-icine-alma</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/face_detect_02.jpg"></p>

<p>İlk yazımda google service api ile bitmap üzerinde face detection'ın nasıl gerçekleştirildiğinden bahsetmeye çalışmıştım. Şimdi ise işi biraz daha ilerletip tanımlanan yüz üzerindeki işlemlerden biraz bahsedicem.</p>

<!-- more -->


<h3>Yüzleri Kare İçine Alma</h3>

<p>Tespit edilen yüzleri kare içerisine almak için <code>Viev</code> sınıfından extend edilen <code>CustomView</code> sınıfını oluşturuyoruz.</p>

<pre><code class="java CustomView.java">package com.ensr.facedetectiondemo;

import android.content.Context;
import android.graphics.Bitmap;
import android.graphics.Canvas;
import android.graphics.Color;
import android.graphics.Paint;
import android.graphics.Rect;
import android.util.AttributeSet;
import android.util.SparseArray;
import android.view.View;

import com.google.android.gms.vision.face.Face;

public class CustomView extends View {

    private Bitmap mBitmap;
    private SparseArray&lt;Face&gt; mFaces;

    public CustomView(Context context, AttributeSet attrs) {
        super(context, attrs);
    }

    void setContent(Bitmap bitmap, SparseArray&lt;Face&gt; faces) {
        mBitmap = bitmap;
        mFaces = faces;
        invalidate();
    }

    @Override
    protected void onDraw(Canvas canvas) {
        super.onDraw(canvas);
        if ((mBitmap != null) &amp;&amp; (mFaces != null)) {
            double scale = drawBitmap(canvas);
            drawFaceRectangle(canvas, scale);
        }
    }

    private double drawBitmap(Canvas canvas) {
        double viewWidth = canvas.getWidth();
        double viewHeight = canvas.getHeight();
        double imageWidth = mBitmap.getWidth();
        double imageHeight = mBitmap.getHeight();
        double scale = Math.min(viewWidth / imageWidth, viewHeight / imageHeight);

        Rect destBounds = new Rect(0, 0, (int)(imageWidth * scale), (int)(imageHeight * scale));
        canvas.drawBitmap(mBitmap, null, destBounds, null);
        return scale;
    }

    private void drawFaceRectangle(Canvas canvas, double scale) {
        Paint paint = new Paint();
        paint.setColor(Color.GREEN);
        paint.setStyle(Paint.Style.STROKE);
        paint.setStrokeWidth(5);

        for (int i = 0; i &lt; mFaces.size(); ++i) {
            Face face = mFaces.valueAt(i);
            canvas.drawRect((float)(face.getPosition().x * scale),
                (float)(face.getPosition().y * scale),
                (float)((face.getPosition().x + face.getWidth()) * scale),
                (float)((face.getPosition().y + face.getHeight()) * scale),
                paint);
        }
    }

}
</code></pre>

<p>Yukarıdaki kodda <code>onDraw</code> methodunu override ediyoruz ve tespit edilen yüzleri kare içerisine alması için <code>drawFaceRectangle</code> fonksitonunu çağırıyoruz.</p>

<p>Daha sonra activity_main.xml'imi şu şekilde değiştiriyoruz.</p>

<pre><code class="xml activity_main.xml">&lt;RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
            xmlns:tools="http://schemas.android.com/tools"
            android:layout_width="match_parent"
            android:layout_height="match_parent"
            tools:context=".MainActivity"&gt;

    &lt;com.ensr.facedetectiondemo.CustomView
        android:id="@+id/customView"
        android:layout_width="match_parent"
        android:layout_height="match_parent" /&gt;

&lt;/RelativeLayout&gt;
</code></pre>

<p>MainActivity'de daha önceki yazımda oluşturduğumuz <code>TextView</code>&lsquo;ı kaldırıp şu şekilde güncelliyoruz.</p>

<pre><code class="java MainActivity.java">@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    InputStream stream = getResources().openRawResource(R.raw.image01);
    Bitmap bitmap = BitmapFactory.decodeStream(stream);

    FaceDetector detector = new FaceDetector.Builder(getApplicationContext())
            .setTrackingEnabled(false)
            .build();

    Frame frame = new Frame.Builder().setBitmap(bitmap).build();
    SparseArray&lt;Face&gt; faces = detector.detect(frame);

    // CustonView i oluştur, bitmap ve tespit edilen yüzlerin listesini ver
    CustomView overlay = (CustomView) findViewById(R.id.customView);
    overlay.setContent(bitmap, faces);

    detector.release();

}
</code></pre>

<p>Evet bu uygulamayı bu haliyle çalıştırdığımızda ekran görüntünüz şunun gibi bişey olacaktır.</p>

<p><img class="center" src="/images/face_detect_03.png"></p>

<p>Şimdilik bu kadar bir sonraki yazımda göz burun ve ağız gibi yüzün bazı bölgelerinin yerlerinin tespit edilmesinden bahsetmeye çalışıcam. Umarım yazımı faydalı bulmuşsunuzdur. Kafanıza takılan bişey olursa yorum yazmaktan çekinmeyin.</p>

<p>İyi günler.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Android Face Detection 01 - Başlangıç]]></title>
    <link href="http://ensr.github.io/blog/2016/02/18/android-face-detection-01/"/>
    <updated>2016-02-18T15:45:52+02:00</updated>
    <id>http://ensr.github.io/blog/2016/02/18/android-face-detection-01</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/face_detect.png"></p>

<p>Android'de face detection işlemini gerçekleştirmek için Google Play Service'i kullanabiliriz.Bunun için yapmamız gereken ilk şey google play service'in gradle dependences'ini projemize eklemek olacaktır.</p>

<p>Android Studio'da oluşturduğumuz projemizin /app dizini altındaki build.gradle dosyasını açarak dependencies kısmına aşşağıdaki satırı ekliyoruz ve Sync ediyoruz.</p>

<!-- more -->


<pre><code class="xml build.gradle">compile 'com.google.android.gms:play-services:7.8.0'
</code></pre>

<p>Bir sonraki adımımız AndroidManifest.xml dosyasına aşağıda verdiğimiz meta-data'yı application tag'inin içerisine eklemek.</p>

<pre><code class="xml AndroidManifest.xml">&lt;meta-data android:name="com.google.android.gms.vision.DEPENDENCIES" android:value="face"/&gt;
</code></pre>

<p>Daha sonra yüz tesbiti yapacağımız resimi /res/raw dizinine koyuyoruz. MainActivity.java'yı (Main activity) açarak aşağıdaki kodu onCreate'in içerisine yazıyoruz.</p>

<pre><code class="java MainActivity.java">@Override
protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    // Resimi bitmap formatına döndürüyoruz.
    InputStream stream = getResources().openRawResource(R.raw.image01);
    Bitmap bitmap = BitmapFactory.decodeStream(stream);

    // Face Detector'ü burada oluşturuyoruz.
    FaceDetector detector = new FaceDetector.Builder(getApplicationContext())
            .setTrackingEnabled(false)
            .build();

    // Bitmap'imiz üzerinde face detection'un çalışması için bir frame oluşturuyoruz.
    Frame frame = new Frame.Builder().setBitmap(bitmap).build();

    // Face detector'ü çalıştırarak resimde belirlenen yüzleri SparseArray'e listeliyoruz.
    SparseArray&lt;Face&gt; faces = detector.detect(frame);

    //Ekrana resimde kaç yüz tespit edildiğini gösteriyoruz.
    TextView faceCountView = (TextView) findViewById(R.id.face_count);
    faceCountView.setText(faces.size() + " faces detected");

    //face detection'u sonlandırıyoruz.
    detector.release();

}
</code></pre>

<p>Evet arkadaşlar, bu şekilde bir resimde yüz olup olmadığını varsa kaç tane olduklarını tespit edebilirsiniz. Şunu da söylemem gerek google'ın bu servisi sadece yüz tespit etmeye yarar, yüz tanıma gibi bir özelliği bulunmamaktadır.</p>

<p>Umarım yardımcı olabilmişimdir. İyi çalışmalar.</p>
]]></content>
  </entry>
  
</feed>
